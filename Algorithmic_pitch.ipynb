{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr0uzFpMXmC3JmR2nlKgLL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yahia-kilany/Algorithm-Pitch-Huffman-vs-LZW/blob/main/Algorithmic_pitch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import heapq\n",
        "from collections import defaultdict\n",
        "import math"
      ],
      "metadata": {
        "id": "TZG_PfhgdGDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HuffmanNode:\n",
        "    def __init__(self, char, freq):\n",
        "        self.char = char\n",
        "        self.freq = freq\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "    def __lt__(self, other):\n",
        "        return self.freq < other.freq\n",
        "\n",
        "def build_frequency_table(text):\n",
        "    freq = defaultdict(int)\n",
        "    for c in text:\n",
        "        freq[c] += 1\n",
        "    return freq\n",
        "\n",
        "def build_huffman_tree(freq):\n",
        "    heap = []\n",
        "    for char, count in freq.items():\n",
        "        heapq.heappush(heap, HuffmanNode(char, count))\n",
        "    if len(heap) == 1:\n",
        "        node = heapq.heappop(heap)\n",
        "        root = HuffmanNode(None, node.freq)\n",
        "        root.left = node\n",
        "        return root\n",
        "    while len(heap) > 1:\n",
        "        left = heapq.heappop(heap)\n",
        "        right = heapq.heappop(heap)\n",
        "        merged = HuffmanNode(None, left.freq + right.freq)\n",
        "        merged.left = left\n",
        "        merged.right = right\n",
        "        heapq.heappush(heap, merged)\n",
        "    return heapq.heappop(heap)\n",
        "\n",
        "def generate_codes(root):\n",
        "    code_map = {}\n",
        "    def traverse(node, current):\n",
        "        if not node:\n",
        "            return\n",
        "        if node.char is not None:\n",
        "            code_map[node.char] = current\n",
        "        traverse(node.left, current + \"0\")\n",
        "        traverse(node.right, current + \"1\")\n",
        "    traverse(root, \"\")\n",
        "    return code_map\n",
        "\n",
        "def huffman_encode(text):\n",
        "    freq = build_frequency_table(text)\n",
        "    tree = build_huffman_tree(freq)\n",
        "    codes = generate_codes(tree)\n",
        "    encoded = \"\".join(codes[c] for c in text)\n",
        "    return encoded, tree\n",
        "\n",
        "def huffman_decode(encoded, root):\n",
        "    result = []\n",
        "    node = root\n",
        "    for bit in encoded:\n",
        "        node = node.left if bit == \"0\" else node.right\n",
        "        if node.char:\n",
        "            result.append(node.char)\n",
        "            node = root\n",
        "    return \"\".join(result)\n",
        "\n",
        "def test_huffman():\n",
        "    test_cases = {\n",
        "        \"small\": \"hello\",\n",
        "        \"repetitive\": \"aaaaaaabaaaaaaabaaaaaaab\",\n",
        "        \"random\": \"the quick brown fox jumps over the lazy dog\",\n",
        "        \"numbers\": \"123123123123123123\",\n",
        "        \"special_chars\": \"!@#!@#!@#!@#\",\n",
        "    }\n",
        "\n",
        "    for name, text in test_cases.items():\n",
        "        print(f\"Testing: {name} (len={len(text)})\")\n",
        "        compressed, tree = huffman_encode(text)  # unpack tuple\n",
        "        decompressed = huffman_decode(compressed, tree)  # pass encoded and tree\n",
        "\n",
        "        print(\"Original:\", text)\n",
        "        print(\"Compressed:\", compressed)\n",
        "        print(\"Decompressed:\", decompressed)\n",
        "        print(\"Test Passed:\", decompressed == text)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Call the test function\n",
        "test_huffman()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTuvnnJYcf0s",
        "outputId": "0fe50cf0-47fd-44bd-bdb1-e3a8e797b645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: small (len=5)\n",
            "Original: hello\n",
            "Compressed: 0001111110\n",
            "Decompressed: hello\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n",
            "Testing: repetitive (len=24)\n",
            "Original: aaaaaaabaaaaaaabaaaaaaab\n",
            "Compressed: 111111101111111011111110\n",
            "Decompressed: aaaaaaabaaaaaaabaaaaaaab\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n",
            "Testing: random (len=43)\n",
            "Original: the quick brown fox jumps over the lazy dog\n",
            "Compressed: 111101110010100010010100010011011001100110001101110110101101011011100010111101010110000101101100001110011111111110001011001010101101100111101110010100011111011101111101011000100110000010110100\n",
            "Decompressed: the quick brown fox jumps over the lazy dog\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n",
            "Testing: numbers (len=18)\n",
            "Original: 123123123123123123\n",
            "Compressed: 101101011010110101101011010110\n",
            "Decompressed: 123123123123123123\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n",
            "Testing: special_chars (len=12)\n",
            "Original: !@#!@#!@#!@#\n",
            "Compressed: 10110101101011010110\n",
            "Decompressed: !@#!@#!@#!@#\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lzw_compress(text, max_dict_size=4096):\n",
        "    dictionary = {chr(i): i for i in range(256)}\n",
        "    next_code = 256\n",
        "    s = \"\"\n",
        "    output = []\n",
        "\n",
        "    for c in text:\n",
        "        if s + c in dictionary:\n",
        "            s = s + c\n",
        "        else:\n",
        "            output.append(dictionary[s])\n",
        "            # Only add to dictionary if we haven't reached the limit\n",
        "            if next_code < max_dict_size:\n",
        "                dictionary[s + c] = next_code\n",
        "                next_code += 1\n",
        "            s = c\n",
        "\n",
        "    if s:\n",
        "        output.append(dictionary[s])\n",
        "    return output\n",
        "\n",
        "def lzw_decompress(encoded, max_dict_size=4096):\n",
        "    dictionary = {i: chr(i) for i in range(256)}\n",
        "    next_code = 256\n",
        "    result = []\n",
        "    prev = encoded[0]\n",
        "    result.append(dictionary[prev])\n",
        "\n",
        "    for code in encoded[1:]:\n",
        "        if code in dictionary:\n",
        "            entry = dictionary[code]\n",
        "        else:\n",
        "            entry = dictionary[prev] + dictionary[prev][0]\n",
        "        result.append(entry)\n",
        "\n",
        "        # Only add to dictionary if we haven't reached the limit\n",
        "        if next_code < max_dict_size:\n",
        "            dictionary[next_code] = dictionary[prev] + entry[0]\n",
        "            next_code += 1\n",
        "        prev = code\n",
        "\n",
        "    return \"\".join(result)\n",
        "def test_lzw():\n",
        "    test_cases = {\n",
        "        \"small\": \"hello\",\n",
        "        \"repetitive\": \"aaaaaaabaaaaaaabaaaaaaab\",\n",
        "        \"random\": \"the quick brown fox jumps over the lazy dog\",\n",
        "        \"numbers\": \"123123123123123123\",\n",
        "        \"special_chars\": \"!@#!@#!@#!@#\",\n",
        "    }\n",
        "\n",
        "    for name, text in test_cases.items():\n",
        "        print(f\"Testing: {name} (len={len(text)})\")\n",
        "        compressed = lzw_compress(text)\n",
        "        decompressed = lzw_decompress(compressed)\n",
        "\n",
        "        print(\"Original:\", text)\n",
        "        print(\"Compressed:\", compressed)\n",
        "        print(\"Decompressed:\", decompressed)\n",
        "        print(\"Test Passed:\", decompressed == text)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Call the test function\n",
        "test_lzw()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VctoEvxBbxgs",
        "outputId": "0621e93c-1625-4f8d-bf1c-23d9e7509031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: small (len=5)\n",
            "Original: hello\n",
            "Compressed: [104, 101, 108, 108, 111]\n",
            "Decompressed: hello\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n",
            "Testing: repetitive (len=24)\n",
            "Original: aaaaaaabaaaaaaabaaaaaaab\n",
            "Compressed: [97, 256, 257, 97, 98, 258, 257, 260, 261, 259]\n",
            "Decompressed: aaaaaaabaaaaaaabaaaaaaab\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n",
            "Testing: random (len=43)\n",
            "Original: the quick brown fox jumps over the lazy dog\n",
            "Compressed: [116, 104, 101, 32, 113, 117, 105, 99, 107, 32, 98, 114, 111, 119, 110, 32, 102, 111, 120, 32, 106, 117, 109, 112, 115, 32, 111, 118, 101, 114, 32, 256, 258, 108, 97, 122, 121, 32, 100, 111, 103]\n",
            "Decompressed: the quick brown fox jumps over the lazy dog\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n",
            "Testing: numbers (len=18)\n",
            "Original: 123123123123123123\n",
            "Compressed: [49, 50, 51, 256, 258, 257, 259, 262, 257]\n",
            "Decompressed: 123123123123123123\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n",
            "Testing: special_chars (len=12)\n",
            "Original: !@#!@#!@#!@#\n",
            "Compressed: [33, 64, 35, 256, 258, 257, 259]\n",
            "Decompressed: !@#!@#!@#!@#\n",
            "Test Passed: True\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgPkBCOEVLBm",
        "outputId": "9ae10c10-e6dd-42c1-8db4-c84b025c9bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: structured_data_size1 (len=990)\n",
            "Testing: skewed_freq_size1 (len=1000)\n",
            "Testing: uniform_random_size1 (len=1000)\n",
            "Testing: structured_data_size2 (len=4950)\n",
            "Testing: skewed_freq_size2 (len=5000)\n",
            "Testing: uniform_random_size2 (len=5000)\n",
            "Testing: structured_data_size3 (len=9996)\n",
            "Testing: skewed_freq_size3 (len=10000)\n",
            "Testing: uniform_random_size3 (len=10000)\n",
            "Testing: structured_data_size4 (len=19992)\n",
            "Testing: skewed_freq_size4 (len=20000)\n",
            "Testing: uniform_random_size4 (len=20000)\n",
            "Testing: structured_data_size5 (len=34968)\n",
            "Testing: skewed_freq_size5 (len=35000)\n",
            "Testing: uniform_random_size5 (len=35000)\n",
            "Testing: structured_data_size6 (len=49995)\n",
            "Testing: skewed_freq_size6 (len=50000)\n",
            "Testing: uniform_random_size6 (len=50000)\n",
            "Testing: structured_data_size7 (len=74970)\n",
            "Testing: skewed_freq_size7 (len=75000)\n",
            "Testing: uniform_random_size7 (len=75000)\n",
            "Testing: structured_data_size8 (len=99975)\n",
            "Testing: skewed_freq_size8 (len=100000)\n",
            "Testing: uniform_random_size8 (len=100000)\n",
            "Testing: structured_data_size9 (len=149989)\n",
            "Testing: skewed_freq_size9 (len=150000)\n",
            "Testing: uniform_random_size9 (len=150000)\n",
            "Testing: structured_data_size10 (len=199971)\n",
            "Testing: skewed_freq_size10 (len=200000)\n",
            "Testing: uniform_random_size10 (len=200000)\n",
            "\n",
            "✓ Saved overall results to: compression_results/all_results.csv\n",
            "✓ Saved structured_data results to: compression_results/structured_data.csv\n",
            "✓ Saved skewed_freq results to: compression_results/skewed_freq.csv\n",
            "✓ Saved uniform_random results to: compression_results/uniform_random.csv\n",
            "\n",
            "================================================================================\n",
            "COMPRESSION COMPARISON SUMMARY\n",
            "================================================================================\n",
            "                  test  original_bits  original_KB  huffman_data  huffman_tree  huffman_total  huffman_KB  lzw_total  lzw_KB  huffman_ratio_%  lzw_ratio_%  huffman_time_ms  lzw_time_ms\n",
            " structured_data_size1           7920         0.97          4180           228           4408        0.54       3168    0.39            44.34        60.00            0.278        0.278\n",
            "     skewed_freq_size1           8000         0.98          2205           200           2405        0.29       2052    0.25            69.94        74.35            0.198        0.252\n",
            "  uniform_random_size1           8000         0.98          5939           690           6629        0.81      10884    1.33            17.14       -36.05            0.345        0.358\n",
            " structured_data_size2          39600         4.83         20070           228          20298        2.48       8040    0.98            48.74        79.70            0.788        1.045\n",
            "     skewed_freq_size2          40000         4.88         11084           184          11268        1.38       6468    0.79            71.83        83.83            0.786        1.399\n",
            "  uniform_random_size2          40000         4.88         29799           690          30489        3.72      44268    5.40            23.78       -10.67            0.957        1.588\n",
            " structured_data_size3          79968         9.76         41208           228          41436        5.06      11460    1.40            48.18        85.67            1.695        2.160\n",
            "     skewed_freq_size3          80000         9.77         22173           184          22357        2.73      10800    1.32            72.05        86.50            1.582        2.007\n",
            "  uniform_random_size3          80000         9.77         59619           690          60309        7.36      81048    9.89            24.61        -1.31            1.774        3.112\n",
            " structured_data_size4         159936        19.52         82416           228          82644       10.09      16380    2.00            48.33        89.76            3.145        4.050\n",
            "     skewed_freq_size4         160000        19.53         44354           184          44538        5.44      18456    2.25            72.16        88.47            2.920        4.025\n",
            "  uniform_random_size4         160000        19.53        119264           690         119954       14.64     153900   18.79            25.03         3.81            3.238        4.535\n",
            " structured_data_size5         279744        34.15        152520           250         152770       18.65      21228    2.59            45.39        92.41            5.109        6.980\n",
            "     skewed_freq_size5         280000        34.18         77673           184          77857        9.50      28680    3.50            72.19        89.76            5.061        7.169\n",
            "  uniform_random_size5         280000        34.18        208773           690         209463       25.57     263472   32.16            25.19         5.90            5.665        8.130\n",
            " structured_data_size6         399960        48.82        209979           239         210218       25.66      27504    3.36            47.44        93.12            7.582        9.834\n",
            "     skewed_freq_size6         400000        48.83        110940           184         111124       13.56      38172    4.66            72.22        90.46            7.222       10.591\n",
            "  uniform_random_size6         400000        48.83        298262           690         298952       36.49     375636   45.85            25.26         6.09            8.146       10.196\n",
            " structured_data_size7         599760        73.21        320460           250         320710       39.15      32580    3.98            46.53        94.57           11.389       14.625\n",
            "     skewed_freq_size7         600000        73.24        166533           184         166717       20.35      52848    6.45            72.21        91.19           10.973       15.383\n",
            "  uniform_random_size7         600000        73.24        447394           690         448084       54.70     555948   67.86            25.32         7.34           12.164       16.224\n",
            " structured_data_size8         799800        97.63        411525           217         411742       50.26      34632    4.23            48.52        95.67           17.279       20.356\n",
            "     skewed_freq_size8         800000        97.66        222022           184         222206       27.12      67560    8.25            72.22        91.55           14.779       21.696\n",
            "  uniform_random_size8         800000        97.66        596598           690         597288       72.91     741420   90.51            25.34         7.32           16.806       19.507\n",
            " structured_data_size9        1199912       146.47        612200           217         612417       74.76      45420    5.54            48.96        96.21           23.148       31.806\n",
            "     skewed_freq_size9        1200000       146.48        333018           184         333202       40.67      96732   11.81            72.23        91.94           24.825       34.489\n",
            "  uniform_random_size9        1200000       146.48        894937           690         895627      109.33    1108776  135.35            25.36         7.60           26.352       31.300\n",
            "structured_data_size10        1599768       195.28        866541           250         866791      105.81      54168    6.61            45.82        96.61           32.753       41.171\n",
            "    skewed_freq_size10        1600000       195.31        444025           184         444209       54.22     125712   15.35            72.24        92.14           29.212       45.875\n",
            " uniform_random_size10        1600000       195.31       1193274           690        1193964      145.75    1476936  180.29            25.38         7.69           34.638       45.090\n",
            "\n",
            "✓ All results saved to CSV files in 'compression_results' folder\n"
          ]
        }
      ],
      "source": [
        "def calculate_huffman_tree_size(codes):\n",
        "    \"\"\"\n",
        "    Calculate the size needed to store the Huffman tree/codebook.\n",
        "    We store it as: (character, code_length) pairs.\n",
        "    - Each character: 8 bits\n",
        "    - Code length: ceil(log2(max_code_length + 1)) bits per entry\n",
        "    - Plus we need to store the number of entries\n",
        "    \"\"\"\n",
        "    if not codes:\n",
        "        return 0\n",
        "\n",
        "    num_chars = len(codes)\n",
        "    max_code_len = max(len(code) for code in codes.values())\n",
        "\n",
        "    # Bits to store number of unique characters (up to 256 for ASCII)\n",
        "    header_bits = 8\n",
        "\n",
        "    # Bits per character entry: 8 bits for char + bits for code length\n",
        "    bits_for_length = math.ceil(math.log2(max_code_len + 1))\n",
        "    bits_per_entry = 8 + bits_for_length\n",
        "\n",
        "    total_bits = header_bits + (num_chars * bits_per_entry)\n",
        "\n",
        "    return total_bits\n",
        "\n",
        "def calculate_lzw_bit_size(compressed, max_dict_size=4096):\n",
        "    \"\"\"\n",
        "    Calculate actual bit size needed to store LZW output.\n",
        "    With a fixed maximum dictionary size, we can use fixed-width codes.\n",
        "    \"\"\"\n",
        "    if not compressed:\n",
        "        return 0\n",
        "    # Use fixed width based on max dictionary size for consistent encoding\n",
        "    bits_per_code = math.ceil(math.log2(max_dict_size))\n",
        "    return len(compressed) * bits_per_code\n",
        "\n",
        "def generate_tests(num_variants=5):\n",
        "    \"\"\"Generate test cases with multiple random variants and increasing sizes\"\"\"\n",
        "    tests = {}\n",
        "\n",
        "    # Define target sizes in characters (all test cases will have same size)\n",
        "    target_sizes = [1000, 5000, 10000, 20000, 35000, 50000, 75000, 100000, 150000, 200000][:num_variants]\n",
        "\n",
        "    for idx, target_size in enumerate(target_sizes):\n",
        "        suffix = f\"_size{idx+1}\"\n",
        "        size_kb = round(target_size / 1024, 1)\n",
        "\n",
        "        # 1. Structured data (HTML-like) - LZW dominates\n",
        "        tags = [\"div\", \"span\", \"p\", \"section\", \"article\"]\n",
        "        classes = [\"container\", \"content\", \"wrapper\", \"box\"]\n",
        "        tag = random.choice(tags)\n",
        "        cls = random.choice(classes)\n",
        "\n",
        "        # Calculate repetitions needed to reach target size\n",
        "        pattern = f\"<{tag} class='{cls}'><p>Content here</p></{tag}>\\n\"\n",
        "        reps = target_size // len(pattern)\n",
        "        tests[f\"structured_data{suffix}\"] = pattern * reps\n",
        "\n",
        "        # 2. Skewed frequency distribution - Huffman's theoretical strength\n",
        "        tests[f\"skewed_freq{suffix}\"] = (\n",
        "            \"a\" * (target_size // 2) +\n",
        "            \"b\" * (target_size // 4) +\n",
        "            \"c\" * (target_size // 8) +\n",
        "            \"\".join(random.choice(\"defghijklmnop\") for _ in range(target_size // 8))\n",
        "        )\n",
        "\n",
        "        # 3. Uniform random - worst case for both\n",
        "        tests[f\"uniform_random{suffix}\"] = \"\".join(\n",
        "            random.choice(string.ascii_letters + string.digits)\n",
        "            for _ in range(target_size)\n",
        "        )\n",
        "\n",
        "    return tests\n",
        "\n",
        "def benchmark_algorithms(num_variants=5, lzw_max_dict=4096, output_dir=\"compression_results\"):\n",
        "    \"\"\"\n",
        "    Run benchmarks and save results to CSV files.\n",
        "\n",
        "    Args:\n",
        "        num_variants: Number of size variants to generate (default: 5)\n",
        "        lzw_max_dict: Maximum LZW dictionary size (default: 4096)\n",
        "        output_dir: Directory to save CSV files (default: \"compression_results\")\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    tests = generate_tests(num_variants)\n",
        "    results = []\n",
        "\n",
        "    for name, text in tests.items():\n",
        "        print(f\"Testing: {name} (len={len(text)})\")\n",
        "\n",
        "        # Original size in bits (8 bits per character)\n",
        "        original_bits = len(text) * 8\n",
        "\n",
        "        # Huffman\n",
        "        start = time.time()\n",
        "        encoded, tree = huffman_encode(text)\n",
        "        codes = generate_codes(tree)\n",
        "        huffman_time = time.time() - start\n",
        "        huffman_data_bits = len(encoded)\n",
        "        huffman_tree_bits = calculate_huffman_tree_size(codes)\n",
        "        huffman_total_bits = huffman_data_bits + huffman_tree_bits\n",
        "\n",
        "        # LZW with limited dictionary\n",
        "        start = time.time()\n",
        "        compressed = lzw_compress(text, max_dict_size=lzw_max_dict)\n",
        "        lzw_time = time.time() - start\n",
        "        lzw_total_bits = calculate_lzw_bit_size(compressed, max_dict_size=lzw_max_dict)\n",
        "\n",
        "        # Calculate compression ratios (using total size including overhead)\n",
        "        huffman_ratio = (1 - huffman_total_bits / original_bits) * 100\n",
        "        lzw_ratio = (1 - lzw_total_bits / original_bits) * 100\n",
        "\n",
        "        results.append({\n",
        "            \"test\": name,\n",
        "            \"original_bits\": original_bits,\n",
        "            \"original_KB\": round(original_bits / 8192, 2),\n",
        "            \"huffman_data\": huffman_data_bits,\n",
        "            \"huffman_tree\": huffman_tree_bits,\n",
        "            \"huffman_total\": huffman_total_bits,\n",
        "            \"huffman_KB\": round(huffman_total_bits / 8192, 2),\n",
        "            \"lzw_total\": lzw_total_bits,\n",
        "            \"lzw_KB\": round(lzw_total_bits / 8192, 2),\n",
        "            \"huffman_ratio_%\": round(huffman_ratio, 2),\n",
        "            \"lzw_ratio_%\": round(lzw_ratio, 2),\n",
        "            \"huffman_time_ms\": round(huffman_time * 1000, 3),\n",
        "            \"lzw_time_ms\": round(lzw_time * 1000, 3)\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Save overall results\n",
        "    overall_csv = os.path.join(output_dir, \"all_results.csv\")\n",
        "    df.to_csv(overall_csv, index=False)\n",
        "    print(f\"\\n✓ Saved overall results to: {overall_csv}\")\n",
        "\n",
        "    # Save separate CSV for each test case type\n",
        "    test_types = [\"structured_data\", \"skewed_freq\", \"uniform_random\"]\n",
        "    for test_type in test_types:\n",
        "        test_df = df[df['test'].str.contains(test_type)]\n",
        "        if not test_df.empty:\n",
        "            test_csv = os.path.join(output_dir, f\"{test_type}.csv\")\n",
        "            test_df.to_csv(test_csv, index=False)\n",
        "            print(f\"✓ Saved {test_type} results to: {test_csv}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# LZW dictionary limited to 4096 entries (12 bits per code)\n",
        "# Results saved to CSV files in 'compression_results' folder\n",
        "df = benchmark_algorithms(num_variants=10, lzw_max_dict=4096, output_dir=\"compression_results\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPRESSION COMPARISON SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(df.to_string(index=False))\n",
        "print(\"\\n✓ All results saved to CSV files in 'compression_results' folder\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TjsMVCx2mEMj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}